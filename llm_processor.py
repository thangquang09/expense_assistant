#!/usr/bin/env python3
"""
LLM Processor for Expense Tracker
Handles LLM-based parsing with Pydantic schemas
"""

import os
import re
import datetime
import logging
from typing import Dict, Optional, Any, List
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from config import get_current_model, get_model_settings

# Suppress verbose langchain retry logs
logging.getLogger("langchain_google_genai").setLevel(logging.ERROR)
logging.getLogger("langchain_ollama").setLevel(logging.ERROR)
logging.getLogger("httpx").setLevel(logging.ERROR)

# Load environment variables
load_dotenv()

# Global flag ƒë·ªÉ track tr·∫°ng th√°i k·∫øt n·ªëi
_llm_available = True
_offline_warning_shown = False


# Pydantic Models for LLM Response Schemas
class IntentAnalysis(BaseModel):
    """Schema for intent analysis results"""
    intent: str = Field(description="Intent category: add_expense, delete_expense, update_balance, view_statistics, unknown")
    confidence: float = Field(description="Confidence level (0.0-1.0)", ge=0.0, le=1.0)
    analysis: str = Field(description="Brief analysis of the user's intent")

class ExpenseInfo(BaseModel):
    """Schema for expense extraction results"""
    food_item: str = Field(description="Name of food/drink or transaction description")
    price: float = Field(description="Price amount as number")
    meal_time: Optional[str] = Field(default=None, description="Meal time: s√°ng, tr∆∞a, chi·ªÅu, t·ªëi, or specific time")
    transaction_type: str = Field(default="expense", description="Transaction type: expense or income")
    account_type: str = Field(default="cash", description="Account type: cash or account")
    confidence: float = Field(description="Confidence level (0.0-1.0)", ge=0.0, le=1.0)

class BalanceUpdate(BaseModel):
    """Schema for balance update analysis"""
    is_balance_update: bool = Field(description="Whether this is a balance update request")
    operation_type: str = Field(description="Operation type: set or add")
    cash_balance: Optional[float] = Field(default=None, description="Cash balance to set (for SET operations)")
    account_balance: Optional[float] = Field(default=None, description="Account balance to set (for SET operations)")
    cash_amount: Optional[float] = Field(default=None, description="Cash amount to add/subtract (for ADD operations)")
    account_amount: Optional[float] = Field(default=None, description="Account amount to add/subtract (for ADD operations)")
    description: str = Field(description="Brief description of the operation")

class DeleteInfo(BaseModel):
    """Schema for delete transaction analysis"""
    food_item: Optional[str] = Field(default=None, description="Food item to delete")
    price: Optional[float] = Field(default=None, description="Price of transaction to delete")
    meal_time: Optional[str] = Field(default=None, description="Meal time of transaction to delete")
    delete_recent: bool = Field(default=False, description="Whether to delete the most recent transaction")
    confidence: float = Field(description="Confidence level (0.0-1.0)", ge=0.0, le=1.0)

class StatisticsInfo(BaseModel):
    """Schema for statistics request analysis"""
    period: str = Field(description="Statistics period: daily, weekly, monthly")
    specific_date: Optional[str] = Field(default=None, description="Specific date if requested")
    confidence: float = Field(description="Confidence level (0.0-1.0)", ge=0.0, le=1.0)

def create_llm_instance():
    """T·∫°o instance LLM d·ª±a tr√™n c·∫•u h√¨nh hi·ªán t·∫°i"""
    global _llm_available
    
    try:
        current_model = get_current_model()
        model_settings = get_model_settings(current_model)
        provider = model_settings["provider"]
        
        if provider == "google":
            # Google Gemini
            api_key = os.getenv(model_settings["api_key_env"])
            if not api_key:
                print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y {model_settings['api_key_env']} - chuy·ªÉn sang ch·∫ø ƒë·ªô offline")
                return None
            
            from langchain_google_genai import ChatGoogleGenerativeAI
            
            return ChatGoogleGenerativeAI(
                model=model_settings["model_name"],
                google_api_key=api_key,
                temperature=0.1
            )
            
        elif provider == "ollama":
            # Ollama models
            try:
                from langchain_ollama import ChatOllama
                
                # Test Ollama connection
                if not _test_ollama_connection(model_settings["base_url"]):
                    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi Ollama t·∫°i {model_settings['base_url']}")
                    print("üí° H√£y kh·ªüi ƒë·ªông Ollama: ollama serve")
                    return None
                
                return ChatOllama(
                    model=model_settings["model_name"],
                    base_url=model_settings["base_url"],
                    temperature=0.1
                )
                
            except ImportError:
                print("‚ö†Ô∏è C·∫ßn c√†i ƒë·∫∑t langchain-ollama: uv add langchain-ollama")
                return None
        
        else:
            print(f"‚ö†Ô∏è Provider kh√¥ng h·ªó tr·ª£: {provider}")
            return None
            
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o LLM: {e}")
        return None

def _test_ollama_connection(base_url: str) -> bool:
    """Test k·∫øt n·ªëi ƒë·∫øn Ollama server"""
    try:
        import requests
        response = requests.get(f"{base_url}/api/tags", timeout=3)
        return response.status_code == 200
    except Exception:
        return False

class QueryAnalyzer:
    def __init__(self):
        """Kh·ªüi t·∫°o LLM processor"""
        global _llm_available
        
        # Ki·ªÉm tra global flag tr∆∞·ªõc
        if not _llm_available:
            self.llm = None
            return
            
        try:
            # Test connection nhanh tr∆∞·ªõc khi kh·ªüi t·∫°o LLM
            if not self._test_connection():
                print("‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt n·ªëi internet - chuy·ªÉn sang ch·∫ø ƒë·ªô offline")
                _llm_available = False
                self.llm = None
                return
            
            # S·ª≠ d·ª•ng h√†m create_llm_instance chung
            self.llm = create_llm_instance()
            
            if self.llm is None:
                _llm_available = False
                
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o QueryAnalyzer: {e} - chuy·ªÉn sang ch·∫ø ƒë·ªô offline")
            _llm_available = False
            self.llm = None
    
    def _test_connection(self) -> bool:
        """Test k·∫øt n·ªëi internet nhanh"""
        try:
            import requests
            requests.get("https://www.google.com", timeout=2)
            return True
        except:
            return False
    
    def analyze_intent(self, user_message: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch intent c·ªßa user message v·ªõi LLM
        Returns: Dict v·ªõi keys: intent, confidence, analysis
        """
        global _llm_available
        
        if not _llm_available or not self.llm:
            return self._fallback_intent_analysis(user_message)
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=IntentAnalysis)
        
        system_prompt = """
        B·∫°n l√† chuy√™n gia ph√¢n t√≠ch intent t·ª´ c√¢u chat ti·∫øng Vi·ªát.
        
        Ph√¢n lo·∫°i intent:
        - "add_expense": th√™m chi ti√™u, ƒÉn, u·ªëng, mua, chi ti√™u, tr·∫£ ti·ªÅn
        - "delete_expense": x√≥a, h·ªßy, xo√° giao d·ªãch
        - "update_balance": c·∫≠p nh·∫≠t s·ªë d∆∞, set balance, th√™m ti·ªÅn v√†o t√†i kho·∫£n
        - "view_statistics": th·ªëng k√™, xem b√°o c√°o, t·ªïng k·∫øt
        - "unknown": kh√¥ng r√µ r√†ng
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nPh√¢n t√≠ch:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # Create chain
            chain = prompt_template | self.llm | parser
            
            # Invoke chain - NO timeout
            response = chain.invoke({"user_message": user_message})
            
            # Convert Pydantic model to dict
            result = {
                'intent': response.intent,
                'confidence': response.confidence,
                'analysis': response.analysis,
                'offline_mode': False
            }
            
            return result
                
        except Exception as e:
            error_msg = str(e)
            
            # Handle quota errors quietly
            if "quota" in error_msg.lower() or "429" in error_msg:
                if _llm_available:  # Only show once
                    print("‚ö†Ô∏è LLM quota exceeded")
                _llm_available = False
            else:
                print(f"‚ö†Ô∏è L·ªói khi g·ªçi LLM: {error_msg[:50]}...")
                _llm_available = False
                
            # Fallback v·ªÅ rule-based parsing
            return self._fallback_intent_analysis(user_message)
    
    def _fallback_intent_analysis(self, message: str) -> Dict[str, Any]:
        """Fallback rule-based intent analysis khi LLM th·∫•t b·∫°i"""
        message_lower = message.lower()
        
        # Simple keyword-based intent detection
        if any(word in message_lower for word in ['x√≥a', 'xo√°', 'h·ªßy', 'delete']):
            intent = 'delete_expense'
            confidence = 0.8
        elif any(word in message_lower for word in ['th·ªëng k√™', 'statistic', 'b√°o c√°o', 't·ªïng k·∫øt']):
            intent = 'view_statistics'
            confidence = 0.8
        elif any(word in message_lower for word in ['s·ªë d∆∞', 'balance', 't√†i kho·∫£n', 'set']):
            intent = 'update_balance'
            confidence = 0.7
        elif any(word in message_lower for word in ['ƒÉn', 'u·ªëng', 'mua', 'chi ti√™u', 'tr·∫£ ti·ªÅn']):
            intent = 'add_expense'
            confidence = 0.9
        else:
            intent = 'add_expense'  # Default to expense
            confidence = 0.5
        
        return {
            'intent': intent,
            'confidence': confidence,
            'analysis': f'Rule-based detection: {intent}',
            'offline_mode': True
        }

class ExpenseExtractor:
    def __init__(self):
        """Kh·ªüi t·∫°o LLM processor"""
        global _llm_available
        
        # Ki·ªÉm tra global flag tr∆∞·ªõc
        if not _llm_available:
            self.llm = None
            return
            
        try:
            # S·ª≠ d·ª•ng h√†m create_llm_instance chung
            self.llm = create_llm_instance()
            
            if self.llm is None:
                _llm_available = False
                
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o ExpenseExtractor: {e}")
            _llm_available = False
            self.llm = None
    
    def extract_expense_info(self, user_message: str) -> Dict[str, Any]:
        """
        Tr√≠ch xu·∫•t th√¥ng tin chi ti√™u t·ª´ tin nh·∫Øn c·ªßa user v·ªõi Pydantic
        Returns: Dict v·ªõi c√°c keys: food_item, price, meal_time, confidence
        """
        global _llm_available
        
        if not _llm_available or not self.llm:
            return self._fallback_extraction(user_message)
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=ExpenseInfo)
        
        # Enhanced system prompt optimized for Llama3
        system_prompt = """
        B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin t√†i ch√≠nh t·ª´ vƒÉn b·∫£n ti·∫øng Vi·ªát.
        
        Ph√¢n lo·∫°i transaction_type:
        - "income": l√£nh l∆∞∆°ng, nh·∫≠n ti·ªÅn, thu nh·∫≠p, ƒë∆∞·ª£c tr·∫£, ti·ªÅn th∆∞·ªüng, ti·ªÅn l∆∞∆°ng
        - "expense": ƒÉn, u·ªëng, mua, chi ti√™u, tr·∫£ ti·ªÅn, m·∫•t ti·ªÅn, ti√™u
        
        Ph√¢n lo·∫°i account_type (QUAN TR·ªåNG):
        - "cash": ti·ªÅn m·∫∑t, cash, ti·ªÅn l·∫ª, ti·ªÅn t√∫i
        - "account": t√†i kho·∫£n, ng√¢n h√†ng, chuy·ªÉn kho·∫£n, ck, bank, atm, banking
        
        QUAN TR·ªåNG - Price parsing:
        - N·∫øu c√≥ "k" ·ªü cu·ªëi s·ªë: nh√¢n v·ªõi 1000 (v√≠ d·ª•: 35k = 35000, 5000k = 5000000)
        - N·∫øu kh√¥ng c√≥ "k": gi·ªØ nguy√™n s·ªë
        
        QUAN TR·ªåNG - Account type keywords:
        - "ck" = "chuy·ªÉn kho·∫£n" ‚Üí account_type PH·∫¢I L√Ä "account"
        - "bank" = "ng√¢n h√†ng" ‚Üí account_type PH·∫¢I L√Ä "account"  
        - "chuy·ªÉn kho·∫£n" ‚Üí account_type PH·∫¢I L√Ä "account"
        - "cash" = "ti·ªÅn m·∫∑t" ‚Üí account_type PH·∫¢I L√Ä "cash"
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nTr√≠ch xu·∫•t:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # Create chain
            chain = prompt_template | self.llm | parser
            
            # Invoke chain - NO timeout
            response = chain.invoke({"user_message": user_message})
            
            # Convert Pydantic model to dict
            result = {
                'food_item': response.food_item,
                'price': response.price,
                'meal_time': response.meal_time,
                'transaction_type': response.transaction_type,
                'account_type': response.account_type,
                'confidence': response.confidence,
                'offline_mode': False
            }
            
            # Validate and fix result
            return self._validate_and_fix_llm_result(result, user_message)
                
        except Exception as e:
            error_msg = str(e)
            
            # Handle quota errors quietly
            if "quota" in error_msg.lower() or "429" in error_msg:
                if _llm_available:  # Only show once
                    print("‚ö†Ô∏è LLM quota exceeded")
                _llm_available = False
            else:
                print(f"‚ö†Ô∏è L·ªói khi g·ªçi LLM: {error_msg[:50]}...")
                _llm_available = False
                
            # Fallback v·ªÅ rule-based parsing
            return self._fallback_extraction(user_message)
    
    def extract_delete_info(self, user_message: str) -> Dict[str, Any]:
        """
        Tr√≠ch xu·∫•t th√¥ng tin giao d·ªãch c·∫ßn x√≥a v·ªõi Pydantic
        Returns: Dict v·ªõi keys: food_item, price (optional), meal_time (optional)
        """
        
        if not self.llm:
            return self._fallback_delete_extraction(user_message)
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=DeleteInfo)
        
        system_prompt = """
        B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin giao d·ªãch c·∫ßn x√≥a t·ª´ c√¢u chat.
        
        Ph√¢n t√≠ch c√¢u chat v√† x√°c ƒë·ªãnh:
        1. C√≥ ph·∫£i mu·ªën x√≥a giao d·ªãch g·∫ßn nh·∫•t kh√¥ng
        2. Ho·∫∑c x√≥a giao d·ªãch c·ª• th·ªÉ (theo t√™n m√≥n, gi√°, th·ªùi gian)
        
        T·ª´ kh√≥a x√≥a g·∫ßn nh·∫•t: "x√≥a", "g·∫ßn nh·∫•t", "recent", ho·∫∑c ƒë·ªÉ tr·ªëng
        T·ª´ kh√≥a x√≥a c·ª• th·ªÉ: t√™n m√≥n ƒÉn, gi√° ti·ªÅn, th·ªùi gian b·ªØa ƒÉn
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nPh√¢n t√≠ch:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # Create chain
            chain = prompt_template | self.llm | parser
            
            # Invoke chain - NO timeout
            response = chain.invoke({"user_message": user_message})
            
            # Convert Pydantic model to dict
            result = {
                'food_item': response.food_item,
                'price': response.price,
                'meal_time': response.meal_time,
                'delete_recent': response.delete_recent,
                'confidence': response.confidence,
                'offline_mode': False
            }
            
            return result
                
        except Exception as e:
            error_msg = str(e)
            print(f"‚ö†Ô∏è L·ªói khi g·ªçi LLM: {error_msg[:50]}...")
            return self._fallback_delete_extraction(user_message)
    
    def _fallback_delete_extraction(self, message: str) -> Dict[str, Any]:
        """Fallback rule-based delete extraction khi LLM th·∫•t b·∫°i"""
        message_lower = message.lower()
        
        # Simple keyword-based detection
        if any(word in message_lower for word in ['x√≥a', 'xo√°', 'h·ªßy', 'delete']):
            if any(word in message_lower for word in ['g·∫ßn nh·∫•t', 'recent', 'cu·ªëi']):
                return {
                    'food_item': None,
                    'price': None,
                    'meal_time': None,
                    'delete_recent': True,
                    'confidence': 0.8,
                    'offline_mode': True
                }
            else:
                # Try to extract specific info
                return {
                    'food_item': None,
                    'price': None,
                    'meal_time': None,
                    'delete_recent': True,  # Default to recent
                    'confidence': 0.6,
                    'offline_mode': True
                }
        
        return {
            'food_item': None,
            'price': None,
            'meal_time': None,
            'delete_recent': False,
            'confidence': 0.3,
            'offline_mode': True
        }
    
    def _validate_and_fix_llm_result(self, result: Dict[str, Any], original_message: str) -> Dict[str, Any]:
        """Validate v√† fix k·∫øt qu·∫£ t·ª´ LLM"""
        
        # Validate price (x·ª≠ l√Ω ƒë∆°n v·ªã k)
        if 'price' in result:
            price = result['price']
            # N·∫øu price qu√° nh·ªè v√† message ch·ª©a 'k', c√≥ th·ªÉ LLM ƒë√£ miss ƒë∆°n v·ªã
            if price < 1000 and ('k' in original_message.lower() or 'K' in original_message):
                # T√¨m s·ªë c√≥ 'k' trong message
                price_match = re.search(r'(\d+)k', original_message.lower())
                if price_match:
                    result['price'] = float(price_match.group(1)) * 1000
                    print(f"üîß Fixed price: {price} ‚Üí {result['price']}")
        
        # Validate account_type for "ck" keyword
        if 'account_type' in result and 'ck' in original_message.lower():
            if result['account_type'] != 'account':
                result['account_type'] = 'account'
                print(f"üîß Fixed account_type: {result['account_type']} ‚Üí account (ck detected)")
        
        return result
    
    def _fallback_extraction(self, message: str) -> Dict[str, Any]:
        """Fallback rule-based extraction khi LLM th·∫•t b·∫°i"""
        result = {
            'food_item': '',
            'price': 0.0,
            'meal_time': None,
            'transaction_type': 'expense',
            'account_type': 'cash',
            'confidence': 0.3,
            'offline_mode': True
        }
        
        message_lower = message.lower()
        confidence_boost = 0.0
        
        # Ph√¢n t√≠ch transaction_type
        income_keywords = ['l√£nh l∆∞∆°ng', 'nh·∫≠n ti·ªÅn', 'thu nh·∫≠p', 'ƒë∆∞·ª£c tr·∫£', 'ti·ªÅn th∆∞·ªüng', 'ti·ªÅn l∆∞∆°ng']
        if any(keyword in message_lower for keyword in income_keywords):
            result['transaction_type'] = 'income'
            confidence_boost += 0.2
        
        # Ph√¢n t√≠ch account_type - Enhanced for llama3 testing
        account_keywords = ['t√†i kho·∫£n', 'ng√¢n h√†ng', 'account', 'atm', 'banking', 'chuy·ªÉn kho·∫£n', 'v√†o t√†i kho·∫£n', 'ck', 'bank']
        cash_keywords = ['ti·ªÅn m·∫∑t', 'cash', 'ti·ªÅn l·∫ª', 'ti·ªÅn t√∫i']
        
        # Special handling for "ck" - must be account
        if 'ck' in message_lower or 'chuy·ªÉn kho·∫£n' in message_lower:
            result['account_type'] = 'account'
            confidence_boost += 0.2  # High confidence for explicit keywords
        elif any(keyword in message_lower for keyword in account_keywords):
            result['account_type'] = 'account'
            confidence_boost += 0.1
        elif any(keyword in message_lower for keyword in cash_keywords):
            result['account_type'] = 'cash'
            confidence_boost += 0.1
        
        # Enhanced price parsing - Fixed for large numbers
        import re
        price_patterns = [
            r'(\d+)k\b',  # 35k, 5000k
            r'(\d+)000\b',  # 35000
            r'(\d+)\s*ngh√¨n\b',  # 35 ngh√¨n
            r'(\d+\.\d+)k\b',  # 35.5k
        ]
        
        for pattern in price_patterns:
            match = re.search(pattern, message_lower)
            if match:
                price_str = match.group(1)
                if 'k' in pattern or 'ngh√¨n' in pattern:
                    # Fixed: Always multiply by 1000 for "k" suffix
                    result['price'] = float(price_str) * 1000
                else:
                    result['price'] = float(price_str)
                confidence_boost += 0.2  # C√≥ gi√° ti·ªÅn r√µ r√†ng
                break
        
        # T√¨m m√≥n ƒÉn/m√¥ t·∫£ giao d·ªãch
        words = message.split()
        for word in words:
            word_clean = re.sub(r'\d+k?', '', word.lower()).strip()
            # Lo·∫°i b·ªè c√°c t·ª´ th·ªùi gian v√† action
            skip_words = ['s√°ng', 'tr∆∞a', 'chi·ªÅu', 't·ªëi', 'ƒÉn', 'u·ªëng', 'mua', 'ck', 'bank', 'cash']
            if word_clean not in skip_words and len(word_clean) > 2:
                result['food_item'] = word_clean
                confidence_boost += 0.1
                break
        
        if not result['food_item']:
            if result['transaction_type'] == 'income':
                result['food_item'] = 'l∆∞∆°ng'
            else:
                result['food_item'] = 'chi ti√™u'
        
        # Ph√¢n t√≠ch meal_time
        meal_time_keywords = {
            's√°ng': 's√°ng',
            'tr∆∞a': 'tr∆∞a', 
            'chi·ªÅu': 'chi·ªÅu',
            't·ªëi': 't·ªëi'
        }
        
        for keyword, meal_time in meal_time_keywords.items():
            if keyword in message_lower:
                result['meal_time'] = meal_time
                confidence_boost += 0.1
                break
        
        # C·∫≠p nh·∫≠t confidence
        result['confidence'] = min(0.9, 0.3 + confidence_boost)
        
        return result
    
    def _extract_balance_update_info(self, user_message: str) -> Optional[Dict[str, Any]]:
        """
        Tr√≠ch xu·∫•t th√¥ng tin c·∫≠p nh·∫≠t s·ªë d∆∞ v·ªõi Pydantic
        Returns: Dict v·ªõi balance info ho·∫∑c None
        """
        
        if not self.llm:
            return self._fallback_balance_update(user_message)
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=BalanceUpdate)
        
        system_prompt = """
        B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin c·∫≠p nh·∫≠t s·ªë d∆∞ t·ª´ c√¢u chat.
        
        Ph√¢n t√≠ch:
        1. C√≥ ph·∫£i mu·ªën c·∫≠p nh·∫≠t s·ªë d∆∞ kh√¥ng
        2. Lo·∫°i operation: SET (ƒë·∫∑t s·ªë d∆∞ c·ª• th·ªÉ) ho·∫∑c ADD (th√™m/b·ªõt)
        3. S·ªë ti·ªÅn cho cash v√† account
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nPh√¢n t√≠ch:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # Create chain
            chain = prompt_template | self.llm | parser
            
            # Invoke chain - NO timeout
            response = chain.invoke({"user_message": user_message})
            
            # Convert Pydantic model to dict
            result = {
                'is_balance_update': response.is_balance_update,
                'operation_type': response.operation_type,
                'cash_balance': response.cash_balance,
                'account_balance': response.account_balance,
                'cash_amount': response.cash_amount,
                'account_amount': response.account_amount,
                'description': response.description,
                'offline_mode': False
            }
            
            return result if result['is_balance_update'] else None
                
        except Exception as e:
            error_msg = str(e)
            print(f"‚ö†Ô∏è L·ªói khi g·ªçi LLM: {error_msg[:50]}...")
            return self._fallback_balance_update(user_message)
    
    def _fallback_balance_update(self, message: str) -> Optional[Dict[str, float]]:
        """Fallback rule-based balance update extraction"""
        message_lower = message.lower()
        
        # Simple keyword detection
        balance_keywords = ['s·ªë d∆∞', 'balance', 't√†i kho·∫£n', 'set']
        if not any(keyword in message_lower for keyword in balance_keywords):
            return None
        
        # Try to extract amounts
        import re
        amounts = re.findall(r'(\d+)k', message_lower)
        if amounts:
            amount = float(amounts[0]) * 1000
            return {
                'is_balance_update': True,
                'operation_type': 'set',
                'cash_balance': amount,
                'account_balance': None,
                'cash_amount': None,
                'account_amount': None,
                'description': f'Set balance to {amount}',
                'offline_mode': True
            }
        
        return None
    
    def extract_statistics_info(self, user_message: str) -> Dict[str, Any]:
        """
        Tr√≠ch xu·∫•t th√¥ng tin th·ªëng k√™ v·ªõi Pydantic
        Returns: Dict v·ªõi period v√† specific_date
        """
        
        if not self.llm:
            return self._fallback_statistics_extraction(user_message)
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=StatisticsInfo)
        
        system_prompt = """
        B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin th·ªëng k√™ t·ª´ c√¢u chat.
        
        Ph√¢n t√≠ch:
        1. Period: daily, weekly, monthly
        2. Specific date n·∫øu c√≥
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nPh√¢n t√≠ch:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # Create chain
            chain = prompt_template | self.llm | parser
            
            # Invoke chain - NO timeout
            response = chain.invoke({"user_message": user_message})
            
            # Convert Pydantic model to dict
            result = {
                'period': response.period,
                'specific_date': response.specific_date,
                'confidence': response.confidence,
                'offline_mode': False
            }
            
            return result
                
        except Exception as e:
            error_msg = str(e)
            print(f"‚ö†Ô∏è L·ªói khi g·ªçi LLM: {error_msg[:50]}...")
            return self._fallback_statistics_extraction(user_message)
    
    def _fallback_statistics_extraction(self, message: str) -> Dict[str, Any]:
        """Fallback rule-based statistics extraction"""
        message_lower = message.lower()
        
        # Simple keyword detection
        if 'tu·∫ßn' in message_lower or 'week' in message_lower:
            period = 'weekly'
        elif 'th√°ng' in message_lower or 'month' in message_lower:
            period = 'monthly'
        else:
            period = 'daily'  # Default
        
        return {
            'period': period,
            'specific_date': None,
            'confidence': 0.7,
            'offline_mode': True
        } 