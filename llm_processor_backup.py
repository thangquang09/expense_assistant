import os
import re
import datetime
import logging
from typing import Dict, Optional, Any, List
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from config import get_current_model, get_model_settings

# Suppress verbose langchain retry logs
logging.getLogger("langchain_google_genai").setLevel(logging.ERROR)
logging.getLogger("langchain_ollama").setLevel(logging.ERROR)
logging.getLogger("httpx").setLevel(logging.ERROR)

# Load environment variables
load_dotenv()

# Global flag ƒë·ªÉ track tr·∫°ng th√°i k·∫øt n·ªëi
_llm_available = True
_offline_warning_shown = False


# Pydantic Models for LLM Response Schemas
class IntentAnalysis(BaseModel):
    """Schema for intent analysis results"""
    intent: str = Field(description="Intent category: add_expense, delete_expense, update_balance, view_statistics, unknown")
    confidence: float = Field(description="Confidence level (0.0-1.0)", ge=0.0, le=1.0)
    analysis: str = Field(description="Brief analysis of the user's intent")


class ExpenseInfo(BaseModel):
    """Schema for expense extraction results"""
    food_item: str = Field(description="Name of food/drink or transaction description")
    price: float = Field(description="Price amount as number")
    meal_time: Optional[str] = Field(default=None, description="Meal time: s√°ng, tr∆∞a, chi·ªÅu, t·ªëi, or specific time")
    transaction_type: str = Field(default="expense", description="Transaction type: expense or income")
    account_type: str = Field(default="cash", description="Account type: cash or account")
    confidence: float = Field(description="Confidence level (0.0-1.0)", ge=0.0, le=1.0)


class BalanceUpdate(BaseModel):
    """Schema for balance update analysis"""
    is_balance_update: bool = Field(description="Whether this is a balance update request")
    operation_type: str = Field(description="Operation type: set or add")
    cash_balance: Optional[float] = Field(default=None, description="Cash balance to set (for SET operations)")
    account_balance: Optional[float] = Field(default=None, description="Account balance to set (for SET operations)")
    cash_amount: Optional[float] = Field(default=None, description="Cash amount to add/subtract (for ADD operations)")
    account_amount: Optional[float] = Field(default=None, description="Account amount to add/subtract (for ADD operations)")
    description: str = Field(description="Brief description of the operation")


class DeleteInfo(BaseModel):
    """Schema for delete transaction analysis"""
    food_item: Optional[str] = Field(default=None, description="Food item to delete")
    price: Optional[float] = Field(default=None, description="Price of transaction to delete")
    meal_time: Optional[str] = Field(default=None, description="Meal time of transaction to delete")
    delete_recent: bool = Field(default=False, description="Whether to delete the most recent transaction")
    confidence: float = Field(description="Confidence level (0.0-1.0)", ge=0.0, le=1.0)


class StatisticsInfo(BaseModel):
    """Schema for statistics request analysis"""
    period: str = Field(description="Statistics period: daily, weekly, monthly")
    specific_date: Optional[str] = Field(default=None, description="Specific date if requested")
    confidence: float = Field(description="Confidence level (0.0-1.0)", ge=0.0, le=1.0)


def create_llm_instance():
    """T·∫°o instance LLM d·ª±a tr√™n c·∫•u h√¨nh hi·ªán t·∫°i"""
    global _llm_available
    
    try:
        current_model = get_current_model()
        model_settings = get_model_settings(current_model)
        provider = model_settings["provider"]
        
        if provider == "google":
            # Google Gemini
            api_key = os.getenv(model_settings["api_key_env"])
            if not api_key:
                print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y {model_settings['api_key_env']} - chuy·ªÉn sang ch·∫ø ƒë·ªô offline")
                return None
            
            from langchain_google_genai import ChatGoogleGenerativeAI
            
            return ChatGoogleGenerativeAI(
                model=model_settings["model_name"],
                google_api_key=api_key,
                temperature=0.1
            )
            
        elif provider == "ollama":
            # Ollama models
            try:
                from langchain_ollama import ChatOllama
                
                # Test Ollama connection
                if not _test_ollama_connection(model_settings["base_url"]):
                    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi Ollama t·∫°i {model_settings['base_url']}")
                    print("üí° H√£y kh·ªüi ƒë·ªông Ollama: ollama serve")
                    return None
                
                return ChatOllama(
                    model=model_settings["model_name"],
                    base_url=model_settings["base_url"],
                    temperature=0.1,
                    timeout=30  # 30 gi√¢y timeout cho Ollama
                )
                
            except ImportError:
                print("‚ö†Ô∏è C·∫ßn c√†i ƒë·∫∑t langchain-ollama: uv add langchain-ollama")
                return None
        
        else:
            print(f"‚ö†Ô∏è Provider kh√¥ng h·ªó tr·ª£: {provider}")
            return None
            
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o LLM: {e}")
        return None

def _test_ollama_connection(base_url: str) -> bool:
    """Test k·∫øt n·ªëi ƒë·∫øn Ollama server"""
    try:
        import requests
        response = requests.get(f"{base_url}/api/tags", timeout=3)
        return response.status_code == 200
    except Exception:
        return False

class QueryAnalyzer:
    def __init__(self):
        """Kh·ªüi t·∫°o Query Analyzer ƒë·ªÉ ph√¢n t√≠ch intent"""
        global _llm_available
        
        try:
            # Test connection nhanh tr∆∞·ªõc khi kh·ªüi t·∫°o LLM
            if not self._test_connection():
                print("‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt n·ªëi internet - chuy·ªÉn sang ch·∫ø ƒë·ªô offline")
                _llm_available = False
                self.llm = None
                return
            
            # S·ª≠ d·ª•ng h√†m create_llm_instance m·ªõi
            self.llm = create_llm_instance()
            
            if self.llm is None:
                _llm_available = False
                
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o LLM: {e} - chuy·ªÉn sang ch·∫ø ƒë·ªô offline")
            _llm_available = False
            self.llm = None
    
    def _test_connection(self) -> bool:
        """Test k·∫øt n·ªëi internet nhanh"""
        try:
            import socket
            socket.create_connection(("8.8.8.8", 53), timeout=2)
            return True
        except (OSError, socket.timeout):
            return False
    
    def analyze_intent(self, user_message: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch intent c·ªßa c√¢u chat
        Returns: Dict v·ªõi intent v√† th√¥ng tin li√™n quan
        """
        global _llm_available, _offline_warning_shown
        
        # N·∫øu ƒë√£ bi·∫øt offline, skip LLM ngay
        if not _llm_available or not self.llm:
            if not _offline_warning_shown:
                print("\nüî¥ CH·∫æ ƒê·ªò OFFLINE")
                print("üí° Vui l√≤ng nh·∫≠p r√µ r√†ng h∆°n: 'ƒÉn ph·ªü 30k', 'x√≥a ph·ªü', 'th·ªëng k√™ h√¥m nay'")
                _offline_warning_shown = True
            
            result = self._fallback_intent_analysis(user_message)
            result['offline_mode'] = True
            return result
        
        # Th·ª≠ d√πng LLM v·ªõi error handling c·∫£i thi·ªán
        try:
            return self._analyze_with_llm(user_message)
        except Exception as e:
            error_msg = str(e)
            
            # Check for quota error - fail fast
            if "quota" in error_msg.lower() or "429" in error_msg:
                if not _offline_warning_shown:
                    print("‚ö†Ô∏è LLM quota exceeded - chuy·ªÉn sang offline mode")
                    print("\nüî¥ CHUY·ªÇN SANG CH·∫æ ƒê·ªò OFFLINE")
                    print("üí° Vui l√≤ng nh·∫≠p r√µ r√†ng h∆°n: 'ƒÉn ph·ªü 30k', 'x√≥a ph·ªü', 'th·ªëng k√™ h√¥m nay'")
                    _offline_warning_shown = True
                _llm_available = False
            else:
                print(f"‚ö†Ô∏è LLM kh√¥ng kh·∫£ d·ª•ng: {error_msg[:100]}...")
                _llm_available = False
                
                if not _offline_warning_shown:
                    print("\nüî¥ CHUY·ªÇN SANG CH·∫æ ƒê·ªò OFFLINE")
                    print("üí° Vui l√≤ng nh·∫≠p r√µ r√†ng h∆°n: 'ƒÉn ph·ªü 30k', 'x√≥a ph·ªü', 'th·ªëng k√™ h√¥m nay'")
                    _offline_warning_shown = True
            
            result = self._fallback_intent_analysis(user_message)
            result['offline_mode'] = True
            return result
    
    def _analyze_with_llm(self, user_message: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch v·ªõi LLM - v·ªõi timeout v√† Pydantic parser"""
        from langchain.schema import HumanMessage, SystemMessage
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=IntentAnalysis)
        
        system_prompt = """
        B·∫°n l√† chuy√™n gia ph√¢n t√≠ch √Ω ƒë·ªãnh (intent) t·ª´ c√¢u chat v·ªÅ chi ti√™u.
        
        Ph√¢n t√≠ch c√¢u chat v√† x√°c ƒë·ªãnh intent:
        1. "add_expense" - Th√™m giao d·ªãch chi ti√™u ho·∫∑c thu nh·∫≠p
        2. "delete_expense" - X√≥a giao d·ªãch 
        3. "update_balance" - C·∫≠p nh·∫≠t s·ªë d∆∞ t√†i kho·∫£n
        4. "view_statistics" - Xem th·ªëng k√™ 
        5. "unknown" - Kh√¥ng r√µ √Ω ƒë·ªãnh
        
        V√≠ d·ª• ph√¢n lo·∫°i:
        - "ƒÉn ph·ªü 30k" ‚Üí add_expense
        - "l√£nh l∆∞∆°ng 5000k" ‚Üí add_expense  
        - "x√≥a ph·ªü" ‚Üí delete_expense
        - "c·∫≠p nh·∫≠t ti·ªÅn m·∫∑t 200k" ‚Üí update_balance
        - "th·ªëng k√™ h√¥m nay" ‚Üí view_statistics
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nPh√¢n t√≠ch:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # Create chain
            chain = prompt_template | self.llm | parser
            
            # Invoke chain
            response = chain.invoke({"user_message": user_message})
            
            return {
                'intent': response.intent,
                'confidence': response.confidence,
                'analysis': response.analysis,
                'offline_mode': False
            }
        except Exception as e:
            # Fallback to old parsing if Pydantic fails
            return self._parse_intent_response_fallback(str(e), user_message)
    
    def _parse_intent_response_fallback(self, error_msg: str, original_message: str) -> Dict[str, Any]:
        """Fallback parsing when Pydantic fails"""
        print(f"Pydantic parsing failed: {error_msg[:50]}...")
        return self._fallback_intent_analysis(original_message)
    
    def _fallback_intent_analysis(self, message: str) -> Dict[str, Any]:
        """Enhanced rule-based intent analysis cho ch·∫ø ƒë·ªô offline"""
        message_lower = message.lower().strip()
        
        # Enhanced delete patterns
        delete_patterns = [
            r'(x√≥a|xo√°|h·ªßy|b·ªè|delete|remove)',
            r'(x√≥a\s*(giao\s*d·ªãch|transaction))',
            r'(h·ªßy\s*(giao\s*d·ªãch|transaction))'
        ]
        
        # Enhanced balance update patterns  
        balance_patterns = [
            r'(c·∫≠p\s*nh·∫≠t|update).*(s·ªë\s*d∆∞|balance|ti·ªÅn)',
            r'(thi·∫øt\s*l·∫≠p|ƒë·∫∑t|set).*(s·ªë\s*d∆∞|balance)',
            r'(s·ªë\s*d∆∞|balance).*(l√†|th√†nh|=)',
            r'(ti·ªÅn\s*m·∫∑t|cash).*(l√†|th√†nh|ch·ªâ\s*c√≥)',
            r'(t√†i\s*kho·∫£n|account).*(l√†|th√†nh|ch·ªâ\s*c√≥)'
        ]
        
        # Enhanced statistics patterns
        stats_patterns = [
            r'(th·ªëng\s*k√™|statistic|b√°o\s*c√°o|report)',
            r'(h√¥m\s*nay|today|daily)',
            r'(tu·∫ßn|week|weekly)',
            r'(th√°ng|month|monthly)',
            r'(xem|show|hi·ªÉn\s*th·ªã).*(chi\s*ti√™u|expense)'
        ]
        
        confidence = 0.7
        
        # Check patterns
        for pattern in delete_patterns:
            if re.search(pattern, message_lower):
                return {
                    'intent': 'delete_expense',
                    'confidence': confidence,
                    'analysis': 'Detected delete intent from keywords',
                    'offline_mode': True
                }
        
        for pattern in balance_patterns:
            if re.search(pattern, message_lower):
                return {
                    'intent': 'update_balance', 
                    'confidence': confidence,
                    'analysis': 'Detected balance update intent',
                    'offline_mode': True
                }
        
        for pattern in stats_patterns:
            if re.search(pattern, message_lower):
                return {
                    'intent': 'view_statistics',
                    'confidence': confidence,
                    'analysis': 'Detected statistics request',
                    'offline_mode': True
                }
        
        # Default to expense if has price pattern
        price_pattern = r'\d+[k\.]?\d*[k]?'
        if re.search(price_pattern, message_lower):
            return {
                'intent': 'add_expense',
                'confidence': 0.6,
                'analysis': 'Detected potential expense with price',
                'offline_mode': True
            }
        
        return {
            'intent': 'unknown',
            'confidence': 0.3,
            'analysis': 'Could not determine intent clearly',
            'offline_mode': True
        }


class ExpenseExtractor:
    def __init__(self):
        """Kh·ªüi t·∫°o LLM processor v·ªõi m√¥ h√¨nh ƒë∆∞·ª£c c·∫•u h√¨nh"""
        global _llm_available
        
        # Ki·ªÉm tra global flag tr∆∞·ªõc
        if not _llm_available:
            self.llm = None
            return
            
        try:
            # S·ª≠ d·ª•ng h√†m create_llm_instance chung
            self.llm = create_llm_instance()
            
            if self.llm is None:
                _llm_available = False
                
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o ExpenseExtractor: {e}")
            _llm_available = False
            self.llm = None
    
    def extract_expense_info(self, user_message: str) -> Dict[str, Any]:
        """
        Tr√≠ch xu·∫•t th√¥ng tin chi ti√™u t·ª´ tin nh·∫Øn c·ªßa user v·ªõi Pydantic
        Returns: Dict v·ªõi c√°c keys: food_item, price, meal_time, confidence
        """
        global _llm_available
        
        if not _llm_available or not self.llm:
            return self._fallback_extraction(user_message)
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=ExpenseInfo)
        
        # Enhanced system prompt optimized for Llama3
        system_prompt = """
        B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin t√†i ch√≠nh t·ª´ vƒÉn b·∫£n ti·∫øng Vi·ªát.
        
        Ph√¢n lo·∫°i transaction_type:
        - "income": l√£nh l∆∞∆°ng, nh·∫≠n ti·ªÅn, thu nh·∫≠p, ƒë∆∞·ª£c tr·∫£, ti·ªÅn th∆∞·ªüng, ti·ªÅn l∆∞∆°ng
        - "expense": ƒÉn, u·ªëng, mua, chi ti√™u, tr·∫£ ti·ªÅn, m·∫•t ti·ªÅn, ti√™u
        
        Ph√¢n lo·∫°i account_type (QUAN TR·ªåNG):
        - "cash": ti·ªÅn m·∫∑t, cash, ti·ªÅn l·∫ª, ti·ªÅn t√∫i
        - "account": t√†i kho·∫£n, ng√¢n h√†ng, chuy·ªÉn kho·∫£n, ck, bank, atm, banking
        
        QUAN TR·ªåNG - Price parsing:
        - N·∫øu c√≥ "k" ·ªü cu·ªëi s·ªë: nh√¢n v·ªõi 1000 (v√≠ d·ª•: 35k = 35000, 5000k = 5000000)
        - N·∫øu kh√¥ng c√≥ "k": gi·ªØ nguy√™n s·ªë
        
        QUAN TR·ªåNG - Account type keywords:
        - "ck" = "chuy·ªÉn kho·∫£n" ‚Üí account_type PH·∫¢I L√Ä "account"
        - "bank" = "ng√¢n h√†ng" ‚Üí account_type PH·∫¢I L√Ä "account"  
        - "chuy·ªÉn kho·∫£n" ‚Üí account_type PH·∫¢I L√Ä "account"
        - "cash" = "ti·ªÅn m·∫∑t" ‚Üí account_type PH·∫¢I L√Ä "cash"
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nTr√≠ch xu·∫•t:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # G·ªçi LLM v·ªõi timeout
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError("LLM call timeout")
            
            signal.signal(signal.SIGALRM, timeout_handler)
            
            # Timeout kh√°c nhau cho t·ª´ng provider
            current_model = get_current_model()
            model_settings = get_model_settings(current_model)
            provider = model_settings["provider"]
            
            if provider == "ollama":
                signal.alarm(15)  # 15 gi√¢y cho Ollama (model load + inference)
            else:
                signal.alarm(5)   # 5 gi√¢y cho Google API
            
            try:
                # Create chain
                chain = prompt_template | self.llm | parser
                
                # Invoke chain
                response = chain.invoke({"user_message": user_message})
                signal.alarm(0)
                
                # Convert Pydantic model to dict with validation
                result = {
                    'food_item': response.food_item,
                    'price': response.price,
                    'meal_time': response.meal_time,
                    'transaction_type': response.transaction_type,
                    'account_type': response.account_type,
                    'confidence': response.confidence,
                    'offline_mode': False
                }
                
                # Validate and fix result
                return self._validate_and_fix_llm_result(result, user_message)
                
            finally:
                signal.alarm(0)
            
        except Exception as e:
            error_msg = str(e)
            
            # Handle quota errors quietly
            if "quota" in error_msg.lower() or "429" in error_msg:
                if _llm_available:  # Only show once
                    print("‚ö†Ô∏è LLM quota exceeded")
                _llm_available = False
            else:
                print(f"‚ö†Ô∏è L·ªói khi g·ªçi LLM: {error_msg[:50]}...")
                _llm_available = False
                
            # Fallback v·ªÅ rule-based parsing
            return self._fallback_extraction(user_message)
    
    def extract_delete_info(self, user_message: str) -> Dict[str, Any]:
        """
        Tr√≠ch xu·∫•t th√¥ng tin giao d·ªãch c·∫ßn x√≥a v·ªõi Pydantic
        Returns: Dict v·ªõi keys: food_item, price (optional), meal_time (optional)
        """
        
        if not self.llm:
            return self._fallback_delete_extraction(user_message)
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=DeleteInfo)
        
        system_prompt = """
        B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin giao d·ªãch c·∫ßn x√≥a t·ª´ c√¢u chat.
        
        Ph√¢n t√≠ch c√¢u chat v√† x√°c ƒë·ªãnh:
        1. C√≥ ph·∫£i mu·ªën x√≥a giao d·ªãch g·∫ßn nh·∫•t kh√¥ng
        2. Ho·∫∑c x√≥a giao d·ªãch c·ª• th·ªÉ (theo t√™n m√≥n, gi√°, th·ªùi gian)
        
        T·ª´ kh√≥a x√≥a g·∫ßn nh·∫•t: "x√≥a", "g·∫ßn nh·∫•t", "recent", ho·∫∑c ƒë·ªÉ tr·ªëng
        T·ª´ kh√≥a x√≥a c·ª• th·ªÉ: t√™n m√≥n ƒÉn, gi√° ti·ªÅn, th·ªùi gian b·ªØa ƒÉn
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nPh√¢n t√≠ch:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # G·ªçi LLM v·ªõi timeout
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError("LLM timeout")
            
            signal.signal(signal.SIGALRM, timeout_handler)
            
            # Timeout kh√°c nhau cho t·ª´ng provider
            current_model = get_current_model()
            model_settings = get_model_settings(current_model)
            provider = model_settings["provider"]
            
            if provider == "ollama":
                signal.alarm(15)  # 15 gi√¢y cho Ollama
            else:
                signal.alarm(5)   # 5 gi√¢y cho Google API
            
            try:
                # Create chain
                chain = prompt_template | self.llm | parser
                
                # Invoke chain  
                response = chain.invoke({"user_message": user_message})
                signal.alarm(0)
                
                # Convert to expected format
                result = {
                    'food_item': response.food_item,
                    'price': response.price,
                    'meal_time': response.meal_time,
                    'delete_recent': response.delete_recent,
                    'confidence': response.confidence,
                    'offline_mode': False
                }
                
                return result
                
            finally:
                signal.alarm(0)
            
        except Exception as e:
            error_msg = str(e)
            print(f"‚ö†Ô∏è L·ªói delete extraction: {error_msg[:50]}...")
            return self._fallback_delete_extraction(user_message)
    
    def _fallback_delete_extraction(self, message: str) -> Dict[str, Any]:
        """Fallback extraction cho delete"""
        result = {
            'food_item': '',
            'price': None,
            'meal_time': None,
            'confidence': 0.4
        }
        
        # Lo·∫°i b·ªè c√°c t·ª´ kh√≥a x√≥a ƒë·ªÉ t√¨m m√≥n ƒÉn
        message_clean = message.lower()
        delete_words = ['x√≥a', 'xo√°', 'h·ªßy', 'b·ªè', 'delete', 'remove', 'giao d·ªãch']
        for word in delete_words:
            message_clean = message_clean.replace(word, ' ')
        
        # T√¨m gi√° ti·ªÅn
        price_patterns = [r'(\d+)k', r'(\d+)000', r'(\d+)\s*ngh√¨n']
        for pattern in price_patterns:
            match = re.search(pattern, message_clean)
            if match:
                price_str = match.group(1)
                if 'k' in pattern or 'ngh√¨n' in pattern:
                    result['price'] = float(price_str) * 1000
                else:
                    result['price'] = float(price_str)
                break
        
        # T√¨m meal_time
        meal_patterns = {
            's√°ng': ['s√°ng', 'bu·ªïi s√°ng'],
            'tr∆∞a': ['tr∆∞a', 'bu·ªïi tr∆∞a'],
            'chi·ªÅu': ['chi·ªÅu', 'bu·ªïi chi·ªÅu'],
            't·ªëi': ['t·ªëi', 'bu·ªïi t·ªëi']
        }
        
        for meal_time, keywords in meal_patterns.items():
            if any(keyword in message_clean for keyword in keywords):
                result['meal_time'] = meal_time
                break
        
        # T√¨m m√≥n ƒÉn (t·ª´ c√≤n l·∫°i sau khi lo·∫°i b·ªè c√°c t·ª´ kh√≥a)
        food_keywords = ['ƒÉn', 'u·ªëng', 'mua']
        words = message_clean.split()
        
        for i, word in enumerate(words):
            if any(keyword in word for keyword in food_keywords):
                if i + 1 < len(words):
                    result['food_item'] = words[i + 1]
                    break
        
        if not result['food_item']:
            # L·∫•y t·ª´ c√≥ v·∫ª nh∆∞ m√≥n ƒÉn
            for word in words:
                if len(word) > 2 and word not in ['s√°ng', 'tr∆∞a', 'chi·ªÅu', 't·ªëi']:
                    result['food_item'] = word
                    break
        
        if not result['food_item']:
            result['food_item'] = 'Kh√¥ng x√°c ƒë·ªãnh'
        
        return result
    
    def _validate_and_fix_llm_result(self, result: Dict[str, Any], original_message: str) -> Dict[str, Any]:
        """
        Validate v√† fix k·∫øt qu·∫£ t·ª´ LLM, v·ªõi x·ª≠ l√Ω ƒë·∫∑c bi·ªát cho Pydantic results
        """
        
        # Validate v√† fix price (x·ª≠ l√Ω ƒë∆°n v·ªã k)
        if 'price' in result:
            price = result['price']
            # N·∫øu price qu√° nh·ªè v√† message ch·ª©a 'k', c√≥ th·ªÉ LLM ƒë√£ miss ƒë∆°n v·ªã
            if price < 1000 and ('k' in original_message.lower() or 'K' in original_message):
                # T√¨m s·ªë c√≥ 'k' trong message
                price_match = re.search(r'(\d+)k', original_message.lower())
                if price_match:
                    result['price'] = float(price_match.group(1)) * 1000
                    print(f"üîß Fixed price: {price} ‚Üí {result['price']}")
        
        # ƒê·∫£m b·∫£o food_item h·ª£p l·ªá
        food_item = result.get('food_item', '')
        if not food_item or food_item.strip() == '':
            # Th·ª≠ extract t·ª´ original message
            words = original_message.split()
            for word in words:
                if not re.match(r'^\d+[k.]?\d*[k]?$', word.lower()) and word.lower() not in ['ƒÉn', 'u·ªëng', 'mua', 'cash', 'bank', 'ck', 's√°ng', 'tr∆∞a', 'chi·ªÅu', 't·ªëi']:
                    result['food_item'] = word
                    break
            
            if not result.get('food_item'):
                result['food_item'] = 'giao d·ªãch'
                if result.get('confidence', 0.8) > 0.5:
                    result['confidence'] = 0.5
        
        # ƒê·∫£m b·∫£o transaction_type h·ª£p l·ªá
        transaction_type = result.get('transaction_type', 'expense')
        if transaction_type not in ['expense', 'income']:
            # Ph√¢n t√≠ch t·ª´ original message
            message_lower = original_message.lower()
            income_keywords = ['l√£nh l∆∞∆°ng', 'nh·∫≠n ti·ªÅn', 'thu nh·∫≠p', 'ƒë∆∞·ª£c tr·∫£', 'ti·ªÅn th∆∞·ªüng', 'l∆∞∆°ng', 'salary']
            
            if any(keyword in message_lower for keyword in income_keywords):
                transaction_type = 'income'
            else:
                transaction_type = 'expense'
        
        result['transaction_type'] = transaction_type
        
        # ƒê·∫£m b·∫£o account_type h·ª£p l·ªá
        account_type = result.get('account_type', 'cash')
        if account_type not in ['cash', 'account']:
            # Ph√¢n t√≠ch t·ª´ original message  
            message_lower = original_message.lower()
            account_keywords = ['t√†i kho·∫£n', 'ng√¢n h√†ng', 'account', 'atm', 'banking', 'chuy·ªÉn kho·∫£n', 'ck', 'bank']
            cash_keywords = ['ti·ªÅn m·∫∑t', 'cash', 'ti·ªÅn l·∫ª', 'ti·ªÅn t√∫i']
            
            if any(keyword in message_lower for keyword in account_keywords):
                account_type = 'account'
            elif any(keyword in message_lower for keyword in cash_keywords):
                account_type = 'cash'
            else:
                account_type = 'cash'
        
        result['account_type'] = account_type
        
        # ƒê·∫£m b·∫£o confidence trong kho·∫£ng h·ª£p l·ªá
        confidence = result.get('confidence', 0.8)
        result['confidence'] = min(max(confidence, 0.2), 0.95)
        
        return result
    
    def _fallback_extraction(self, message: str) -> Dict[str, Any]:
        """Fallback rule-based extraction khi LLM th·∫•t b·∫°i"""
        result = {
            'food_item': '',
            'price': 0.0,
            'meal_time': None,
            'transaction_type': 'expense',  # Default
            'account_type': 'cash',  # Default
            'confidence': 0.3,  # Base confidence cho fallback
            'offline_mode': True  # Flag ƒë·ªÉ nh·∫≠n bi·∫øt offline mode
        }
        
        message_lower = message.lower()
        confidence_boost = 0.0
        
        # Ph√¢n t√≠ch transaction_type
        income_keywords = ['l√£nh', 'l∆∞∆°ng', 'nh·∫≠n', 'thu', 'ƒë∆∞·ª£c', 'th∆∞·ªüng', 'salary', 'income', 'ti·ªÅn l∆∞∆°ng']
        expense_keywords = ['ƒÉn', 'u·ªëng', 'mua', 'chi', 'ti√™u', 'tr·∫£', 'spend']
        
        if any(keyword in message_lower for keyword in income_keywords):
            result['transaction_type'] = 'income'
            confidence_boost += 0.1
        elif any(keyword in message_lower for keyword in expense_keywords):
            result['transaction_type'] = 'expense'
            confidence_boost += 0.1
        
        # Ph√¢n t√≠ch account_type - Enhanced for llama3 testing
        account_keywords = ['t√†i kho·∫£n', 'ng√¢n h√†ng', 'account', 'atm', 'banking', 'chuy·ªÉn kho·∫£n', 'v√†o t√†i kho·∫£n', 'ck', 'bank']
        cash_keywords = ['ti·ªÅn m·∫∑t', 'cash', 'ti·ªÅn l·∫ª', 'ti·ªÅn t√∫i']
        
        # Special handling for "ck" - must be account
        if 'ck' in message_lower or 'chuy·ªÉn kho·∫£n' in message_lower:
            result['account_type'] = 'account'
            confidence_boost += 0.2  # High confidence for explicit keywords
        elif any(keyword in message_lower for keyword in account_keywords):
            result['account_type'] = 'account'
            confidence_boost += 0.1
        elif any(keyword in message_lower for keyword in cash_keywords):
            result['account_type'] = 'cash'
            confidence_boost += 0.1
        
        # Enhanced price parsing - Fixed for large numbers
        import re
        price_patterns = [
            r'(\d+)k\b',  # 35k, 5000k
            r'(\d+)000\b',  # 35000
            r'(\d+)\s*ngh√¨n\b',  # 35 ngh√¨n
            r'(\d+\.\d+)k\b',  # 35.5k
        ]
        
        for pattern in price_patterns:
            match = re.search(pattern, message_lower)
            if match:
                price_str = match.group(1)
                if 'k' in pattern or 'ngh√¨n' in pattern:
                    # Fixed: Always multiply by 1000 for "k" suffix
                    result['price'] = float(price_str) * 1000
                else:
                    result['price'] = float(price_str)
                confidence_boost += 0.2  # C√≥ gi√° ti·ªÅn r√µ r√†ng
                break
        
        # T√¨m meal_time
        meal_patterns = {
            's√°ng': ['s√°ng', 'bu·ªïi s√°ng'],
            'tr∆∞a': ['tr∆∞a', 'bu·ªïi tr∆∞a', 'lunch'],
            'chi·ªÅu': ['chi·ªÅu', 'bu·ªïi chi·ªÅu', 'afternoon'],
            't·ªëi': ['t·ªëi', 'bu·ªïi t·ªëi', 'dinner', 'supper']
        }
        
        for meal_time, keywords in meal_patterns.items():
            if any(keyword in message_lower for keyword in keywords):
                result['meal_time'] = meal_time
                confidence_boost += 0.15  # C√≥ th·ªùi gian r√µ r√†ng
                break
        
        # T√¨m m√≥n ƒÉn/m√¥ t·∫£ giao d·ªãch - enhanced logic
        food_keywords = ['ƒÉn', 'u·ªëng', 'mua', 'order', 'g·ªçi']
        words = message.split()
        
        # Strategy 1: T√¨m t·ª´ ngay sau food keyword
        for i, word in enumerate(words):
            word_lower = word.lower()
            for keyword in food_keywords:
                if keyword in word_lower and i + 1 < len(words):
                    potential_food = words[i + 1]
                    # Lo·∫°i b·ªè s·ªë ti·ªÅn kh·ªèi t√™n m√≥n
                    potential_food = re.sub(r'\d+k?', '', potential_food).strip()
                    if potential_food and len(potential_food) > 1:
                        result['food_item'] = potential_food
                        confidence_boost += 0.2  # C√≥ m√≥n ƒÉn r√µ r√†ng
                        break
            if result['food_item']:
                break
        
        # Strategy 2: T√¨m m√¥ t·∫£ cho giao d·ªãch thu nh·∫≠p
        if not result['food_item'] and result['transaction_type'] == 'income':
            income_descriptions = ['l∆∞∆°ng', 'th∆∞·ªüng', 'thu nh·∫≠p', 'ti·ªÅn l∆∞∆°ng', 'nh·∫≠n ti·ªÅn']
            for desc in income_descriptions:
                if desc in message_lower:
                    result['food_item'] = desc
                    confidence_boost += 0.15
                    break
        
        # Strategy 3: N·∫øu ch∆∞a t√¨m ƒë∆∞·ª£c, t√¨m t·ª´ c√≥ √Ω nghƒ©a
        if not result['food_item']:
            for word in words:
                word_clean = re.sub(r'\d+k?', '', word.lower()).strip()
                # Lo·∫°i b·ªè c√°c t·ª´ th·ªùi gian v√† action
                skip_words = ['s√°ng', 'tr∆∞a', 'chi·ªÅu', 't·ªëi', 'ƒÉn', 'u·ªëng', 'mua', 'order', 'g·ªçi', 'bu·ªïi', 
                             'l√£nh', 'nh·∫≠n', 't·ª´', 'v√†o', 't√†i', 'kho·∫£n', 'ti·ªÅn', 'm·∫∑t']
                if word_clean not in skip_words and len(word_clean) > 2:
                    result['food_item'] = word_clean
                    confidence_boost += 0.1  # C√≥ t·ª´ nh∆∞ng kh√¥ng ch·∫Øc ch·∫Øn
                    break
        
        # Strategy 4: Fallback - m√¥ t·∫£ chung
        if not result['food_item']:
            if result['transaction_type'] == 'income':
                result['food_item'] = 'thu nh·∫≠p'
            else:
                result['food_item'] = 'chi ti√™u'
        
        # ƒêi·ªÅu ch·ªânh confidence d·ª±a tr√™n s·ªë l∆∞·ª£ng th√¥ng tin t√¨m ƒë∆∞·ª£c
        final_confidence = result['confidence'] + confidence_boost
        
        # Bonus cho input c√≥ format ho√†n ch·ªânh
        if result['price'] > 0 and result['food_item'] not in ['thu nh·∫≠p', 'chi ti√™u']:
            if result['meal_time']:
                final_confidence += 0.1  # Perfect match: c√≥ ƒë·ªß c·∫£ 3 y·∫øu t·ªë
            else:
                final_confidence += 0.05  # Good match: c√≥ m√≥n v√† gi√°
        
        # ƒê·∫£m b·∫£o confidence trong kho·∫£ng h·ª£p l·ªá
        result['confidence'] = min(max(final_confidence, 0.2), 0.9)
        
        return result
    
    def _extract_balance_update_info(self, user_message: str) -> Optional[Dict[str, Any]]:
        """Tr√≠ch xu·∫•t th√¥ng tin c·∫≠p nh·∫≠t s·ªë d∆∞ t·ª´ tin nh·∫Øn v·ªõi Pydantic"""
        global _llm_available
        
        if not _llm_available or not self.llm:
            return self._fallback_balance_update(user_message)
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=BalanceUpdate)
        
        system_prompt = """
        B·∫°n l√† chuy√™n gia ph√¢n t√≠ch c√¢u l·ªánh c·∫≠p nh·∫≠t s·ªë d∆∞ t√†i ch√≠nh.
        
        C√ì 2 LO·∫†I THAO T√ÅC:
        1. THI·∫æT L·∫¨P (SET): ƒê·∫∑t s·ªë d∆∞ v·ªÅ m·ªôt gi√° tr·ªã c·ª• th·ªÉ
        2. C·ªòNG/TR·ª™ (ADD): C·ªông/tr·ª´ v√†o s·ªë d∆∞ hi·ªán t·∫°i
        
        PH√ÇN LO·∫†I THEO T·ª™ KH√ìA:
        - SET: "c·∫≠p nh·∫≠t l·∫°i", "ch·ªâ c√≥", "l√†", "th√†nh", "ƒë·∫∑t l·∫°i", "reset"
        - ADD: "l√£nh l∆∞∆°ng", "nh·∫≠n ti·ªÅn", "thu nh·∫≠p", "chi ti√™u", "m·∫•t ti·ªÅn"
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nPh√¢n t√≠ch:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # G·ªçi LLM v·ªõi timeout ng·∫Øn
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError("LLM timeout")
            
            signal.signal(signal.SIGALRM, timeout_handler)
            
            # Timeout kh√°c nhau cho t·ª´ng provider
            current_model = get_current_model()
            model_settings = get_model_settings(current_model)
            provider = model_settings["provider"]
            
            if provider == "ollama":
                signal.alarm(15)  # 15 gi√¢y cho Ollama
            else:
                signal.alarm(5)   # 5 gi√¢y cho Google API
            
            try:
                # Create chain
                chain = prompt_template | self.llm | parser
                
                # Invoke chain
                response = chain.invoke({"user_message": user_message})
                signal.alarm(0)
                
                # Convert to dict format expected by the rest of the system
                if response.is_balance_update:
                    return {
                        'operation_type': response.operation_type,
                        'cash_balance': response.cash_balance,
                        'account_balance': response.account_balance,
                        'cash_amount': response.cash_amount,
                        'account_amount': response.account_amount,
                        'description': response.description
                    }
                else:
                    return None
                    
            finally:
                signal.alarm(0)
                
        except Exception as e:
            error_msg = str(e)
            
            # Handle quota errors quietly (consistent v·ªõi expense handling)
            if "quota" in error_msg.lower() or "429" in error_msg:
                if _llm_available:  # Only show once per session
                    print("‚ö†Ô∏è LLM quota exceeded")
                _llm_available = False
            elif "timeout" in error_msg.lower():
                # Handle timeout specifically
                if _llm_available:
                    print("‚ö†Ô∏è LLM timeout - chuy·ªÉn sang fallback")
                _llm_available = False
            else:
                print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω balance update: {error_msg[:50]}...")
                
            return self._fallback_balance_update(user_message)
    
    def _fallback_balance_update(self, message: str) -> Optional[Dict[str, float]]:
        """Fallback x·ª≠ l√Ω balance update cho ch·∫ø ƒë·ªô offline"""
        message_lower = message.lower()
        
        # Ki·ªÉm tra c√≥ ph·∫£i balance update kh√¥ng
        balance_keywords = ['c·∫≠p nh·∫≠t', 'update', 'ti·ªÅn m·∫∑t', 't√†i kho·∫£n', 'l√£nh l∆∞∆°ng', 'nh·∫≠n ti·ªÅn', 'chi ti√™u']
        if not any(keyword in message_lower for keyword in balance_keywords):
            return None
        
        # Ph√¢n lo·∫°i operation type
        set_keywords = ['c·∫≠p nh·∫≠t l·∫°i', 'ch·ªâ c√≥', 'l√†', 'th√†nh', 'ƒë·∫∑t l·∫°i', 'reset', 'thi·∫øt l·∫≠p']
        add_keywords = ['l√£nh', 'l∆∞∆°ng', 'nh·∫≠n', 'thu', 'ƒë∆∞·ª£c', 'th∆∞·ªüng', 'chi', 'ti√™u', 'm·∫•t', 'tr·∫£']
        
        is_set_operation = any(keyword in message_lower for keyword in set_keywords)
        is_add_operation = any(keyword in message_lower for keyword in add_keywords)
        
        # T√¨m s·ªë ti·ªÅn
        import re
        amount = 0
        price_patterns = [r'(\d+)k\b', r'(\d+)000\b', r'(\d+)\s*ngh√¨n\b', r'(\d+)\s*tri·ªáu\b']
        for pattern in price_patterns:
            match = re.search(pattern, message_lower)
            if match:
                amount_str = match.group(1)
                if 'tri·ªáu' in pattern:
                    amount = float(amount_str) * 1000000
                elif 'k' in pattern or 'ngh√¨n' in pattern:
                    amount = float(amount_str) * 1000
                else:
                    amount = float(amount_str)
                break
        
        if amount <= 0:
            return None
        
        # X√°c ƒë·ªãnh lo·∫°i t√†i kho·∫£n
        account_keywords = ['t√†i kho·∫£n', 'ng√¢n h√†ng', 'account', 'atm', 'v√†o t√†i kho·∫£n']
        cash_keywords = ['ti·ªÅn m·∫∑t', 'cash', 'ti·ªÅn l·∫ª', 'ti·ªÅn t√∫i']
        
        is_account = any(keyword in message_lower for keyword in account_keywords)
        is_cash = any(keyword in message_lower for keyword in cash_keywords)
        
        balance_update = {}
        
        if is_set_operation:
            # Thi·∫øt l·∫≠p s·ªë d∆∞ (SET)
            if is_account and not is_cash:
                balance_update['account_balance'] = amount
            elif is_cash and not is_account:
                balance_update['cash_balance'] = amount
            else:
                # M·∫∑c ƒë·ªãnh l√† ti·ªÅn m·∫∑t n·∫øu kh√¥ng r√µ
                balance_update['cash_balance'] = amount
        else:
            # C·ªông/tr·ª´ s·ªë d∆∞ (ADD)
            # X√°c ƒë·ªãnh c·ªông hay tr·ª´
            income_keywords = ['l√£nh', 'l∆∞∆°ng', 'nh·∫≠n', 'thu', 'ƒë∆∞·ª£c', 'th∆∞·ªüng', 'c·∫≠p nh·∫≠t', 'c√≤n', 'c√≥']
            expense_keywords = ['chi', 'ti√™u', 'm·∫•t', 'tr·∫£', 'spend']
            
            is_income = any(keyword in message_lower for keyword in income_keywords)
            is_expense = any(keyword in message_lower for keyword in expense_keywords)
            
            if is_expense and not is_income:
                amount = -amount  # Chi ti√™u th√¨ √¢m
            
            if is_account and not is_cash:
                balance_update['account_amount'] = amount
            elif is_cash and not is_account:
                balance_update['cash_amount'] = amount
            else:
                # M·∫∑c ƒë·ªãnh l√† ti·ªÅn m·∫∑t n·∫øu kh√¥ng r√µ
                balance_update['cash_amount'] = amount
        
        return balance_update if balance_update else None
    
    def extract_statistics_info(self, user_message: str) -> Dict[str, Any]:
        """
        Tr√≠ch xu·∫•t th√¥ng tin y√™u c·∫ßu th·ªëng k√™ v·ªõi Pydantic
        Returns: Dict v·ªõi keys: period, specific_date, confidence
        """
        
        if not self.llm:
            return self._fallback_statistics_extraction(user_message)
        
        # Create Pydantic parser
        parser = PydanticOutputParser(pydantic_object=StatisticsInfo)
        
        system_prompt = """
        B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin y√™u c·∫ßu th·ªëng k√™ chi ti√™u.
        
        Ph√¢n t√≠ch c√¢u chat v√† x√°c ƒë·ªãnh:
        1. Kho·∫£ng th·ªùi gian th·ªëng k√™: daily, weekly, monthly
        2. Ng√†y c·ª• th·ªÉ n·∫øu c√≥ (ƒë·ªãnh d·∫°ng YYYY-MM-DD)
        
        T·ª´ kh√≥a nh·∫≠n bi·∫øt:
        - "h√¥m nay", "today" ‚Üí daily
        - "tu·∫ßn", "week" ‚Üí weekly  
        - "th√°ng", "month" ‚Üí monthly
        
        {format_instructions}
        """
        
        prompt_template = PromptTemplate(
            template=system_prompt + "\n\nC√¢u chat: '{user_message}'\n\nPh√¢n t√≠ch:",
            input_variables=["user_message"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        try:
            # G·ªçi LLM v·ªõi timeout
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError("LLM timeout")
            
            signal.signal(signal.SIGALRM, timeout_handler)
            
            # Timeout kh√°c nhau cho t·ª´ng provider
            current_model = get_current_model()
            model_settings = get_model_settings(current_model)
            provider = model_settings["provider"]
            
            if provider == "ollama":
                signal.alarm(15)  # 15 gi√¢y cho Ollama
            else:
                signal.alarm(5)   # 5 gi√¢y cho Google API
            
            try:
                # Create chain
                chain = prompt_template | self.llm | parser
                
                # Invoke chain
                response = chain.invoke({"user_message": user_message})
                signal.alarm(0)
                
                # Convert to expected format
                result = {
                    'period': response.period,
                    'specific_date': response.specific_date,
                    'confidence': response.confidence,
                    'offline_mode': False
                }
                
                return result
                
            finally:
                signal.alarm(0)
            
        except Exception as e:
            error_msg = str(e)
            print(f"‚ö†Ô∏è L·ªói statistics extraction: {error_msg[:50]}...")
            return self._fallback_statistics_extraction(user_message)
    
    def _fallback_statistics_extraction(self, message: str) -> Dict[str, Any]:
        """Rule-based fallback cho statistics extraction"""
        message_lower = message.lower().strip()
        
        # Detect period
        if any(word in message_lower for word in ['h√¥m nay', 'today', 'daily']):
            period = 'daily'
            confidence = 0.8
        elif any(word in message_lower for word in ['tu·∫ßn', 'week', 'weekly']):
            period = 'weekly' 
            confidence = 0.8
        elif any(word in message_lower for word in ['th√°ng', 'month', 'monthly']):
            period = 'monthly'
            confidence = 0.8
        else:
            period = 'daily'  # Default
            confidence = 0.5
        
        return {
            'period': period,
            'specific_date': None,
            'confidence': confidence,
            'offline_mode': True
        } 